{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#F72585\"><center>Tensorborad en tensorflow</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9fec57",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/AprendizajeProfundo/Alejandria/main/Herramientas_Desarrollo/Imagenes/board.jpg\" width=\"600\" height=\"400\" align=\"center\" /> \n",
    "</center>   \n",
    "</figure>\n",
    "<center>\n",
    "\n",
    "Fuente: © Raimond Spekking\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">¿Qué es Tensorborad?</span>\n",
    "\n",
    "Tutorial tomado de [Neptune blog, Deep Dive Into TensorBoard: Tutorial With Examples](https://neptune.ai/blog/tensorboard-tutorial)\n",
    "\n",
    "Es una herramienta que permite rastrear varias métricas como la precisión (accuracy) y los registros de los grupos de pérdida de entrenamiento o de validación. TensorBoard provee distintas aplicaciones para utilizar en experimentos de aprendizaje de máquina. Algunas de las aplicaciones que se pueden ver en las distintas pestañas del tablero de Tensorboard son:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Tablero de tensorBoard</span>\n",
    "\n",
    "- **Scalars**: Muestra los cambios en la perdida y métricas cobre las épocas. también puede usarse para rastrear otros valores escalares como la taza de aprendizaje y la velocidad de entrenamiento.\n",
    "- **Images**: Tiene imágenes que muestran los pesos. parándose con sobre una época especifica se pueden ver los pesos del modelo en esa época.\n",
    "- **Graphs**: Muestra las capas del modelo. Se puede utilizar para revisar si la arquitectura del modelo es la que se pretende.\n",
    "- **Distributions**: Muestra la distribución de los tensores. Por ejemplo, se puede ver la distribución de los pesos y sesgos sobre cada época en una capa específica.\n",
    "- **Histograms**: Muestra la distribución de los tensores sobre el tiempo, sobre cada época.\n",
    "- **Proyector**: Se puede utilizar para visualizar la representación de cada vector, por ejemplo, word embeddings (la representación numérica de las palabras que captura su relación semántica) y imágenes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Requerimientos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import itertools\n",
    "import io\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn import metrics\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Instalación y carga</span>\n",
    "\n",
    "Se puede utlizar ´pip´ o ´conda´ para la **instalación**, observe los siguientes comandos:\n",
    "\n",
    "`pip install tensorboard`\n",
    "\n",
    "`conda install -c conda-forge tensorboard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede **cargar** Tensorboard utilizando Jupyter notebook, Jupyter lab o Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Tensorboard genera unos archivos \"logs\" o \"registros\" del codigo que se ejecuta y que deben ser guaradados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = 'logs1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de querer recargar la extensión se puede utilizar el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para limpiar los `logs` y dejar libre el folder se pueden correr los siguientes comandos:\n",
    "\n",
    "- Para linux: `rm -rf logs`\n",
    "- Para colab: `!rm -rf /logs/`\n",
    "- Para windows utilizar ambos:\n",
    "    - `!taskkill /f /t /im tensorboard.exe`\n",
    "    - `!del /a /s /q /f logs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se estan corriendo distintos experimentos, todos ellos se pueden guardar para luego compararlos creando logs guardados con una marca de tiempo utilizando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: no se encontr� el proceso \"tensorboard.exe\".\n",
      "No se pudo encontrar c:\\Users\\User\\OneDrive\\Documentos\\GitHub\\Libro-Fundamentos\\Herramientas_Desarrollo\\Cuadernos\\logs\n"
     ]
    }
   ],
   "source": [
    "# Clear out any prior log data.\n",
    "!taskkill /f /t /im tensorboard.exe\n",
    "!del /a /s /q /f logs\n",
    "\n",
    "# Sets up a timestamped log directory.\n",
    "log_folder = f\"{log_folder}/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(log_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Ejemplo</span>\n",
    "\n",
    "Usaremos TensorBoard para visualizar las metricas de un modelo. Construiremos para ello un modelo simple de clasificación de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Modelo</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0 #normalización\n",
    "class_names = ['Zero','One','Two','Three','Four','Five','Six','Seven','Eight','Nine']\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Graficando imagenes de entrenamiento con TensorBoard</span>\n",
    "\n",
    "Este tablero (dashboard) tiene imágenes que muestran los pesos. Ajustando con los botones deslizantes los pesos para las distintas épocas.\n",
    "\n",
    "Se puede usar la API de resumen de imágenes de TensorFlow para visualizar las imágenes de entrenamiento. Esto es especialmente útil cuando se trabaja con datos de imágenes como en este caso. Anteriormente se habían especificado las imágenes con un tamaño de 28x28, por eso, es importante reajustar el tamaño de las imágenes antes de escribirlas en TensorFlow. También se necesita especificar el canal a 1 porque las imágenes están en escala de grises. Después, se utuliza la función **file_write** para escribir las imágenes en TensorBoard. \n",
    "\n",
    "En este caso las imágenes indexadas de 10 a 30 serán mostradas en TensorBoar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar imagenes para mostrar en Tensorboard.\n",
    "with file_writer.as_default():\n",
    "    images = np.reshape(X_train[10:30], (-1, 28, 28, 1))\n",
    "    tf.summary.image(\"20 Digits\", images, max_outputs=25, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Tensorboard callback</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para especificar la retrollamada (call back) durante el ajuste del modelo se debe importar Tensorboard. Esta retrollamada es responsable de registrar los eventos como los histogramas de activación, gráficas de resumen de las métricas o gráficos de visualización de perfilado (profiling: duración de ejecución de un código) y entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la retrollamada (callback) y especificamos el directorio de los registros (logs) utilizando el código `log_dir`. Otros de los parámetros que se utilizan son:\n",
    "\n",
    "- `histogram_freq`: Es la frecuencia con la que se computa la activación y pesos de los histogramas por capas del modelo. Cuando se deja en cerp significa que los histogramas no seran computados. Para esto se debe trabajar con un conjunto de validación.\n",
    "- `write_graph`:  Dicta si el gráfico sera visualizaso en TensorBoard.\n",
    "- `write_images`: Cuando es verdadero (True), los pesos del modelo son visualizados como una imagen en TensorBoard\n",
    "- `update_freq_`: Determina como las perdidas y metricas son escritas en TensorBoard. Cuando se establece como un entero, por ejemplo 100, las perdidas y metricas son registradas cada 100 lotes. Cuando se define por lotes, las metricas son establecidas despues de cada lote y cuando se define por epoca, se establecen despues de cada epoca.\n",
    "- `profile_batch`: Determina que lotes (batches) seran medidos (profiled). Por defecto, el segundo lote es medido.\n",
    "- `embeddings_freq`: Frecuencia con que las capas de embedding del modelo son visualizadas, con cero no son visualizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos el modelo llamando la retrollamada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 1.8378 - accuracy: 0.4962 - val_loss: 1.3689 - val_accuracy: 0.7710\n",
      "Epoch 2/8\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 1.1350 - accuracy: 0.7774 - val_loss: 0.8770 - val_accuracy: 0.8373\n",
      "Epoch 3/8\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.7978 - accuracy: 0.8269 - val_loss: 0.6519 - val_accuracy: 0.8652\n",
      "Epoch 4/8\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.6320 - accuracy: 0.8536 - val_loss: 0.5344 - val_accuracy: 0.8822\n",
      "Epoch 5/8\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.5394 - accuracy: 0.8675 - val_loss: 0.4660 - val_accuracy: 0.8922\n",
      "Epoch 6/8\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4822 - accuracy: 0.8793 - val_loss: 0.4213 - val_accuracy: 0.9000\n",
      "Epoch 7/8\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.4429 - accuracy: 0.8859 - val_loss: 0.3901 - val_accuracy: 0.9045\n",
      "Epoch 8/8\n",
      "1869/1875 [============================>.] - ETA: 0s - loss: 0.4132 - accuracy: 0.8910"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=0.000004)\n",
    "\n",
    "model.compile(optimizer=optim,\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_folder, histogram_freq=1)\n",
    "\n",
    "model.fit(x=X_train, \n",
    "        y=y_train, \n",
    "        epochs=8, \n",
    "        validation_data=(X_test, y_test), \n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Ejecución de Tensorboard</span>\n",
    "\n",
    "Se puede ejecutar con alguno de los siguientes códigos:\n",
    "\n",
    "- Si se instaló con pip y se quiere correr en la terminal: `tensorboard --logdir=log`\n",
    "- Si se va a correr en el cuaderno: `%tensorboard --logdir={log_folder}`\n",
    "- Si se desea ver en el navegador: http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir={log_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se desea compartir los resultados obtenidos en Tensorboard basta con oprimir el botón **upload** que pedira correr un comando similar al mostrado a continuación. Resulta mejor correrlo desde la consola o en colab.\n",
    "\n",
    "`tensorboard dev upload --logdir 'logs2/fit/20211121-184313'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Matriz de confusión en TensorBoard</span>\n",
    "\n",
    "Usando el mismo ejemplo, puede registrar la matriz de confusión para todas las épocas. Primero, se define una función que devolverá una figura Matplotlib que mantiene la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):    \n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "\n",
    "    digit = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    digit = tf.expand_dims(digit, 0)\n",
    "\n",
    "    return digit\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names): \n",
    "    figure = plt.figure(figsize=(8, 8)) \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Accent) \n",
    "    plt.title(\"Confusion matrix\") \n",
    "    plt.colorbar() \n",
    "    tick_marks = np.arange(len(class_names)) \n",
    "    plt.xticks(tick_marks, class_names, rotation=45) \n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)  \n",
    "    threshold = cm.max() / 2. \n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):   \n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"   \n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)  \n",
    "    \n",
    "    plt.tight_layout() \n",
    "    plt.ylabel('True label') \n",
    "    plt.xlabel('Predicted label') \n",
    "\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, borramos los registros anteriores, definimos el directorio de registro para la matriz de confusión, y creamos una variable de escritor para escribir en la carpeta de registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out any prior log data.\n",
    "!taskkill /f /t /im tensorboard.exe\n",
    "!del /a /s /q /f logs\n",
    "\n",
    "log_folder2 = 'logs2'\n",
    "# Sets up a timestamped log directory.\n",
    "log_folder2 = f\"{log_folder2}/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(log_folder2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paso que sigue es crear una función que hará predicciones del modelo y registrara la matriz de confusión como una imagen. Después de eso, se utiliza `File_Writer` para escribir la matriz de confusión al directorio de registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(epoch, logs):\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_test, predictions)\n",
    "    figure = plot_confusion_matrix(cm, class_names=class_names)\n",
    "    cm_image = plot_to_image(figure)\n",
    "    \n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto será seguido por la definición de la retrollamada de Tensorboard y el Lambdacallback. El Lambdacallback registrará la matriz de confusión en cada época. Finalmente, se corre el modelo utilizando estos dos callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "   TensorBoard(log_dir=log_folder2, \n",
    "               histogram_freq=1, \n",
    "               write_graph=True,\n",
    "               write_images=True,\n",
    "               update_freq='epoch',\n",
    "               profile_batch=2,\n",
    "               embeddings_freq=1),\n",
    "   keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "]\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=8,\n",
    "          validation_split=0.2,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run TensorBoard and check the confusion matrix on the Images tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir={log_folder2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Ajuste de hiperparámetros con TensorBoard</span>\n",
    "\n",
    "Tensorborad también se puede utilizar para visualizar la optimización de los hiperparámetros, por ejemplo, el número de lotes o la tasa de aprendizaje. Se puede revisar los hiperparámetros del modelo manualmente o usando una optimización automatizada y visualizándolos en TensorBoard. El tablero está disponible bajo la pestaña HPARAMS. Para esto se debe limpiar los registros previos e importar el paquete hparams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out any prior log data.\n",
    "!taskkill /f /t /im tensorboard.exe\n",
    "!del /a /s /q /f logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs3\"\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es definir los parámetros a sintonizar. En este caso, las unidades en la capa densa, la tasa de deserción (dropout rate) y la función del optimizador se sintonizarán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([300, 200,512]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1,0.5))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'rmsprop']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, se usa `tf.summary.create_file_writer` para definir la carpeta donde los registros serán guardados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer(f'{logdir}/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con eso, se debe definir el modelo como se hizo anteriormente sin embargo, la diferencia está en el número de neuronas en la primera capa densa, la tasa de abandono (drop out rate) y la función del optimizador, ya que estas no se codificarán.\n",
    "\n",
    "Esto se hará en una función que se utilizará más adelante, mientras ejecute los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hparams):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(hparams[HP_NUM_UNITS],  activation='relu'),\n",
    "        tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "    model.compile(optimizer=hparams[HP_OPTIMIZER],\n",
    "                  loss='sparse_categorical_crossentropy',  \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=5)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función que se debe crear ejecutará la función anterior utilizando los parámetros definidos anteriormente. Luego se registrará la precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(experiment_dir, hparams):\n",
    "\n",
    "    with tf.summary.create_file_writer(experiment_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        accuracy = create_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de esto, debe ejecutar esta función para todas las combinaciones de los parámetros definidos anteriormente. Cada uno de los experimentos se almacenará en su propia carpeta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_no = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_OPTIMIZER: optimizer,}\n",
    "\n",
    "            experiment_name = f'Experiment {experiment_no}'\n",
    "            print(f'Starting Experiment: {experiment_name}')\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            experiment(f'{logdir}/hparam_tuning/' + experiment_name, hparams)\n",
    "            experiment_no += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se ejecuta Tensorboard para ver la visualización que se vio al comienzo de este notebook. En la pestaña *Hparams*, se muestran todos los modelos corridos y su precisión (accuracy), dropout rate y capas densas. *Parallel Coordinates View* muestra cada corrida como una línea que se mueve a través de un eje para cada uno de los hiperparamétricos y la métrica de precisión. Al hacer clic en uno de ellos, mostrará los ensayos de los hiperparámetros y *Scatter Plot View* visualiza la comparación entre los hiperparaméteres y las métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir={logdir}/hparam_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">TensorFlow Profiler</span>\n",
    "\n",
    "También puede realizar un seguimiento del rendimiento de los modelos de TensorFlow utilizando la herramienta `Profiler` que resulta crucial para comprender el consumo de recursos de recursos de hardware de las operaciones de TensorFlow. Esta herramienta solo está disponible para quienes cuenten con equipos con GPU. Quienes deseen pueden hacer uso especial de la siguiente aplicación de la herramienta:\n",
    "\n",
    "- Input pipeline analyzer: Se puede utilizar para analizar las ineficiencias en la tubería de entrada (input pipeline) del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
