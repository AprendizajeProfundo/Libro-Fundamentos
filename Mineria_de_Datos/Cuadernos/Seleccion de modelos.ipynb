{"cells":[{"cell_type":"markdown","source":"# Selección de modelos","metadata":{"tags":[],"cell_id":"8ca1fbc3fa344a64bc464d548b3f516e","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h1"}},{"cell_type":"markdown","source":"## Optimización de hiperparámetros","metadata":{"tags":[],"cell_id":"8ebcbf1f6b4e46d9a50cb48486c6fd98","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"## Autores","metadata":{"tags":[],"cell_id":"71596ef3-e801-442a-8250-f2acf111abd8","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"Angelica Agudelo (maagudeloro@unal.edu.co)","metadata":{"tags":[],"cell_id":"807c88ff-f5e7-40b4-bc07-eecd71666005","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Pablo González (pgonzalezb@unal.edu.co)","metadata":{"tags":[],"cell_id":"54659fe3-68d3-4ae3-869c-825fe686daf9","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Dana Reyes (dreyesmo@unal.edu.co)","metadata":{"tags":[],"cell_id":"86ca2ec5-c491-4ce5-b287-c6639293e5e8","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"## Referencias","metadata":{"tags":[],"cell_id":"10e18094838e4a4ca9f52850bcc1cde3","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"Selección de modelos: https://scikit-learn.org/stable/model_selection.html#model-selection","metadata":{"tags":[],"cell_id":"9ae8c650-61b5-48a1-a1c5-0bc923ff0282","is_collapsed":false,"formattedRanges":[{"url":"https://scikit-learn.org/stable/model_selection.html#model-selection","type":"link","ranges":[],"toCodePoint":90,"fromCodePoint":22}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Librería para búsqueda por optimización bayesiana: https://optuna.readthedocs.io/en/stable/","metadata":{"tags":[],"cell_id":"8ff05460-6d2a-4d65-94e4-1b445bc1956f","is_collapsed":false,"formattedRanges":[{"url":"https://optuna.readthedocs.io/en/stable/","type":"link","ranges":[],"toCodePoint":91,"fromCodePoint":51}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Librería para búsqueda de grilla: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html","metadata":{"tags":[],"cell_id":"63403943-368d-44e4-86f0-3345e1236411","is_collapsed":false,"formattedRanges":[{"url":"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html","type":"link","ranges":[],"toCodePoint":125,"fromCodePoint":34}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Librería para búsqueda aleatoria: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html","metadata":{"tags":[],"cell_id":"b7f180d1-c9b4-4d4c-9838-78395bd68bd3","is_collapsed":false,"formattedRanges":[{"url":"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html","type":"link","ranges":[],"toCodePoint":131,"fromCodePoint":34}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Nota histórica:","metadata":{"tags":[],"cell_id":"d08822c230e94e109a816627b7590f52","is_collapsed":false,"formattedRanges":[{"url":"https://en.wikipedia.org/wiki/Random_search","type":"link","ranges":[],"toCodePoint":15,"fromCodePoint":15}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"- https://en.wikipedia.org/wiki/Random_search","metadata":{"tags":[],"cell_id":"2197d3550b524b6ab61ee055cfe211c8","is_collapsed":false,"formattedRanges":[{"url":"https://en.wikipedia.org/wiki/Random_search","type":"link","ranges":[],"toCodePoint":43,"fromCodePoint":0}],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- https://en.wikipedia.org/wiki/Random_optimization","metadata":{"tags":[],"cell_id":"3e49ac76-c5db-4d8c-aa73-1cfac024cd0b","is_collapsed":false,"formattedRanges":[{"url":"https://en.wikipedia.org/wiki/Random_optimization","type":"link","ranges":[],"toCodePoint":49,"fromCodePoint":0}],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"- https://en.wikipedia.org/wiki/Bayesian_optimization","metadata":{"tags":[],"cell_id":"3dd10ad8-a2b7-4d4e-a8ec-4600abb6c34e","is_collapsed":false,"formattedRanges":[{"url":"https://en.wikipedia.org/wiki/Bayesian_optimization","type":"link","ranges":[],"toCodePoint":51,"fromCodePoint":0}],"deepnote_cell_type":"text-cell-bullet"}},{"cell_type":"markdown","source":"## Introducción","metadata":{"tags":[],"cell_id":"59b60d0e18134141841a4267fe4b4846","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"Los hiperparámetros son parámetros que no se aprenden directamente dentro de los estimadores. En general, se pasan como argumentos al constructor de las clases del estimador. Cualquier parámetro proporcionado al construir un estimador puede optimizarse con distintos métodos.","metadata":{"tags":[],"cell_id":"70c3b4d8dedb4bc4ac0dded2210eea3e","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"En scikit-learn se proporcionan dos enfoques genéricos para la búsqueda de parámetros: para valores dados, GridSearchCV considera exhaustivamente todas las combinaciones de parámetros, mientras que RandomizedSearchCV puede muestrear una cantidad determinada de candidatos de un espacio de parámetros con una distribución específica.","metadata":{"tags":[],"cell_id":"ce1e2443-460b-4986-82b6-1758014bf8b8","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Por otro lado, el ajuste de hiperparámetros por medio del razonamiento bayesiano, o la optimización bayesiana, puede reducir el tiempo necesario para llegar al conjunto óptimo de parámetros y brindar un mejor rendimiento de generalización en el conjunto de prueba. Lo hace teniendo en cuenta la información sobre las combinaciones de hiperparámetros que ha visto hasta ahora al elegir el conjunto de hiperparámetros para evaluar a continuación. Al elegir sus combinaciones de parámetros de manera informada, se permite enfocarse en aquellas áreas del espacio de parámetros que cree que traerán los puntajes de validación más prometedores. Este enfoque generalmente requiere menos iteraciones para llegar al conjunto óptimo de valores de hiperparámetros.","metadata":{"tags":[],"cell_id":"25faa68e-d8a7-4d95-a7fe-861fd3c728d9","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"A continuación hablaremos de las técnicas utilizadas para evaluar y seleccionar el mejor modelo según un conjunto de posibles valores de hiperparámetros. Revisaremos distintas técnicas de selección de hiperparámetros como por ejemplo una búsqueda aleatoria (random search), búsqueda de grilla (grid search) y optimización bayesiana para la optimización de hiperparámetros.","metadata":{"tags":[],"cell_id":"d03a8ddf-f32d-4142-9142-aa4b14070d78","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Cada sección de este capitulo incluirá un contexto histórico, las definiciones y ecuaciones matemáticas necesarias para entender la técnica desde el punto de vista científico, y una implementación en Python con datos extraídos de Kaggle.","metadata":{"tags":[],"cell_id":"4b18288f-37e4-4668-b6e8-da3525c09a40","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"## Nota histórica","metadata":{"tags":[],"cell_id":"dc668d7a7c57456fa9b925f7a0d9e320","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"Según información sacada de wikipedia. En 1953 la Revista de la Asociación Estadounidense de Estadística publicó un artículo con el nombre \"Recent Advances in Finding Best Operating Conditions\" ('Avances recientes en la búsqueda de las mejores condiciones de funcionamiento') escrito por el doctor R.L. Anderson donde revisó el progreso de los métodos usados para evaluar las condiciones experimentales en las reacciones químicas por varios científicos. El método en general consistía en encontrar el máximo o mínimo de problemas usando una serie de conjeturas distribuidas con un cierto patrón en el espacio de búsqueda, el patrón podía ser la búsqueda por grilla, una búsqueda secuencial en cada parámetro o una combinación de ambos; la búsqueda se aplica secuencialmente a cada parámetro y saca las mejores conjeturas de la última secuencia.","metadata":{"tags":[],"cell_id":"0bbaef270efd407aad0a1f86dca95d6f","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"El término de búsqueda aleatoria se atribuye a Rastrigin, el cual, en una publicación en 1964 llamada \"The convergence of the random search method in the extremal control of a many parameter system\" ('La convergencia del método de búsqueda aleatoria en el control externo de un sistema con muchos parámetros') presenta un análisis matemático básico sobre la búsqueda aleatoria explicando que este método funciona moviéndose iterativamente a mejores posiciones en el espacio de búsqueda, estas posiciones se muestrean por una hiperesfera que rodea la posición actual. Posteriormente, en 1965 se menciona el término de optimización aleatoria en un artículo del mismo nombre realizado por Mátyás, en donde al igual que la búsqueda aleatoria se presenta un análisis matemático básico que explica como funciona este método que hace parte de los métodos de optimización numérica que no requieren que se optimice el gradiente; su funcionamiento es el mismo que en la búsqueda aleatoria, pero las posiciones se muestrean usando una distribución que puede ser normal.","metadata":{"tags":[],"cell_id":"bbafcb3d-cfe6-4416-8360-722fe43d43c2","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Finalmente, Jonas Mockus publica una series de artículos sobre la optimización bayesiana entre las décadas de las 70s y 80s, y en consecuencia, el término de optimización bayesiana se le atribuye.","metadata":{"tags":[],"cell_id":"06c56b48-6a9f-4b7a-9090-0689fb7a5527","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"### Pasos previos (importar datos y ajustar modelo base)","metadata":{"tags":[],"cell_id":"833753082d78401d931456d32a73b6ae","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"markdown","source":"Con el fin de realizar ejemplos con cada una de las técnicas distintas que vamos a exponer, utilizaremos un conjunto de datos muy simple sacado de Kaggle (https://www.kaggle.com/datasets/mirichoi0218/insurance) al cual le ajustaremos un modelo de Potenciación del gradiente (GradientBoosting) para regresión con los hiperparámetros por defecto por lo cual lo usaremos como modelo base, y a este modelo es al que le haremos la optimización de hiperparámetros.","metadata":{"tags":[],"cell_id":"e540fbb44f324ba3985d2e89b9c0d4b5","is_collapsed":false,"formattedRanges":[{"url":"https://www.kaggle.com/datasets/mirichoi0218/insurance","type":"link","ranges":[],"toCodePoint":209,"fromCodePoint":155}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Como métrica de rendimiento, utilizaremos el coeficiente de determinación (R2).","metadata":{"tags":[],"cell_id":"4dccd533-dbae-4ac7-a6e1-fd7845031e53","is_collapsed":false,"formattedRanges":[{"url":"https://en.wikipedia.org/wiki/Coefficient_of_determination","type":"link","ranges":[],"toCodePoint":79,"fromCodePoint":45}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"tags":[],"cell_id":"df7015ff7cb54bc7a112110564b677b4","source_hash":"7958d4a9","execution_start":1669599754094,"execution_millis":3602,"is_output_hidden":true,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /shared-libs/python3.9/py/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.2.5)\nRequirement already satisfied: scikit-learn in /shared-libs/python3.9/py/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.1.2)\nRequirement already satisfied: optuna in /root/venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (3.0.3)\nRequirement already satisfied: hyperopt in /root/venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.2.7)\nRequirement already satisfied: numpy>=1.16.5 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 1)) (1.23.4)\nRequirement already satisfied: pytz>=2017.3 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 1)) (2022.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\nRequirement already satisfied: joblib>=1.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 2)) (3.1.0)\nRequirement already satisfied: scipy>=1.3.2 in /root/venv/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.8.1)\nRequirement already satisfied: tqdm in /shared-libs/python3.9/py/lib/python3.9/site-packages (from optuna->-r requirements.txt (line 3)) (4.64.1)\nRequirement already satisfied: importlib-metadata<5.0.0 in /root/venv/lib/python3.9/site-packages (from optuna->-r requirements.txt (line 3)) (4.13.0)\nRequirement already satisfied: cliff in /root/venv/lib/python3.9/site-packages (from optuna->-r requirements.txt (line 3)) (4.1.0)\nRequirement already satisfied: alembic>=1.5.0 in /root/venv/lib/python3.9/site-packages (from optuna->-r requirements.txt (line 3)) (1.8.1)\nRequirement already satisfied: cmaes>=0.8.2 in /root/venv/lib/python3.9/site-packages (from optuna->-r requirements.txt (line 3)) (0.9.0)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from optuna->-r requirements.txt (line 3)) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from optuna->-r requirements.txt (line 3)) (1.4.42)\nRequirement already satisfied: PyYAML in /root/venv/lib/python3.9/site-packages (from optuna->-r requirements.txt (line 3)) (6.0)\nRequirement already satisfied: colorlog in /root/venv/lib/python3.9/site-packages (from optuna->-r requirements.txt (line 3)) (6.7.0)\nRequirement already satisfied: py4j in /root/venv/lib/python3.9/site-packages (from hyperopt->-r requirements.txt (line 4)) (0.10.9.7)\nRequirement already satisfied: cloudpickle in /root/venv/lib/python3.9/site-packages (from hyperopt->-r requirements.txt (line 4)) (2.2.0)\nRequirement already satisfied: networkx>=2.2 in /root/venv/lib/python3.9/site-packages (from hyperopt->-r requirements.txt (line 4)) (2.8.8)\nRequirement already satisfied: six in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from hyperopt->-r requirements.txt (line 4)) (1.16.0)\nRequirement already satisfied: future in /shared-libs/python3.9/py/lib/python3.9/site-packages (from hyperopt->-r requirements.txt (line 4)) (0.18.2)\nRequirement already satisfied: Mako in /root/venv/lib/python3.9/site-packages (from alembic>=1.5.0->optuna->-r requirements.txt (line 3)) (1.2.4)\nRequirement already satisfied: zipp>=0.5 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from importlib-metadata<5.0.0->optuna->-r requirements.txt (line 3)) (3.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from packaging>=20.0->optuna->-r requirements.txt (line 3)) (3.0.9)\nRequirement already satisfied: greenlet!=0.4.17 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from sqlalchemy>=1.3.0->optuna->-r requirements.txt (line 3)) (1.1.3.post0)\nRequirement already satisfied: autopage>=0.4.0 in /root/venv/lib/python3.9/site-packages (from cliff->optuna->-r requirements.txt (line 3)) (0.5.1)\nRequirement already satisfied: cmd2>=1.0.0 in /root/venv/lib/python3.9/site-packages (from cliff->optuna->-r requirements.txt (line 3)) (2.4.2)\nRequirement already satisfied: PrettyTable>=0.7.2 in /root/venv/lib/python3.9/site-packages (from cliff->optuna->-r requirements.txt (line 3)) (3.5.0)\nRequirement already satisfied: stevedore>=2.0.1 in /root/venv/lib/python3.9/site-packages (from cliff->optuna->-r requirements.txt (line 3)) (4.1.1)\nRequirement already satisfied: pyperclip>=1.6 in /root/venv/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna->-r requirements.txt (line 3)) (1.8.2)\nRequirement already satisfied: attrs>=16.3.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna->-r requirements.txt (line 3)) (22.1.0)\nRequirement already satisfied: wcwidth>=0.1.7 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna->-r requirements.txt (line 3)) (0.2.5)\nRequirement already satisfied: pbr!=2.1.0,>=2.0.0 in /root/venv/lib/python3.9/site-packages (from stevedore>=2.0.1->cliff->optuna->-r requirements.txt (line 3)) (5.11.0)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna->-r requirements.txt (line 3)) (2.0.1)\n\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import r2_score","metadata":{"tags":[],"cell_id":"a2dad40c8a2542bd9fdfb58e2833de50","source_hash":"818c19dc","execution_start":1669599757701,"execution_millis":694,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":2},{"cell_type":"code","source":"data = pd.read_csv('https://raw.githubusercontent.com/pgonzalezb4/MineriaDeDatos-2022-2/main/data/insurance.csv')\ndata.head()","metadata":{"tags":[],"cell_id":"53e2f749d591407992e77dab016cba34","source_hash":"f16b433d","execution_start":1669599758399,"execution_millis":49,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":7,"row_count":5,"columns":[{"name":"age","dtype":"int64","stats":{"unique_count":5,"nan_count":0,"min":"18","max":"33","histogram":[{"bin_start":18,"bin_end":19.5,"count":2},{"bin_start":19.5,"bin_end":21,"count":0},{"bin_start":21,"bin_end":22.5,"count":0},{"bin_start":22.5,"bin_end":24,"count":0},{"bin_start":24,"bin_end":25.5,"count":0},{"bin_start":25.5,"bin_end":27,"count":0},{"bin_start":27,"bin_end":28.5,"count":1},{"bin_start":28.5,"bin_end":30,"count":0},{"bin_start":30,"bin_end":31.5,"count":0},{"bin_start":31.5,"bin_end":33,"count":2}]}},{"name":"sex","dtype":"object","stats":{"unique_count":2,"nan_count":0,"categories":[{"name":"male","count":4},{"name":"female","count":1}]}},{"name":"bmi","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"22.705","max":"33.77","histogram":[{"bin_start":22.705,"bin_end":23.8115,"count":1},{"bin_start":23.8115,"bin_end":24.918,"count":0},{"bin_start":24.918,"bin_end":26.0245,"count":0},{"bin_start":26.0245,"bin_end":27.131,"count":0},{"bin_start":27.131,"bin_end":28.2375,"count":1},{"bin_start":28.2375,"bin_end":29.344,"count":1},{"bin_start":29.344,"bin_end":30.4505,"count":0},{"bin_start":30.4505,"bin_end":31.557000000000002,"count":0},{"bin_start":31.557000000000002,"bin_end":32.6635,"count":0},{"bin_start":32.6635,"bin_end":33.77,"count":2}]}},{"name":"children","dtype":"int64","stats":{"unique_count":3,"nan_count":0,"min":"0","max":"3","histogram":[{"bin_start":0,"bin_end":0.3,"count":3},{"bin_start":0.3,"bin_end":0.6,"count":0},{"bin_start":0.6,"bin_end":0.8999999999999999,"count":0},{"bin_start":0.8999999999999999,"bin_end":1.2,"count":1},{"bin_start":1.2,"bin_end":1.5,"count":0},{"bin_start":1.5,"bin_end":1.7999999999999998,"count":0},{"bin_start":1.7999999999999998,"bin_end":2.1,"count":0},{"bin_start":2.1,"bin_end":2.4,"count":0},{"bin_start":2.4,"bin_end":2.6999999999999997,"count":0},{"bin_start":2.6999999999999997,"bin_end":3,"count":1}]}},{"name":"smoker","dtype":"object","stats":{"unique_count":2,"nan_count":0,"categories":[{"name":"no","count":4},{"name":"yes","count":1}]}},{"name":"region","dtype":"object","stats":{"unique_count":3,"nan_count":0,"categories":[{"name":"southeast","count":2},{"name":"northwest","count":2},{"name":"southwest","count":1}]}},{"name":"charges","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"1725.5523","max":"21984.47061","histogram":[{"bin_start":1725.5523,"bin_end":3751.444131,"count":1},{"bin_start":3751.444131,"bin_end":5777.335962,"count":2},{"bin_start":5777.335962,"bin_end":7803.227793000001,"count":0},{"bin_start":7803.227793000001,"bin_end":9829.119624,"count":0},{"bin_start":9829.119624,"bin_end":11855.011455,"count":0},{"bin_start":11855.011455,"bin_end":13880.903286,"count":0},{"bin_start":13880.903286,"bin_end":15906.795117,"count":0},{"bin_start":15906.795117,"bin_end":17932.686948000002,"count":1},{"bin_start":17932.686948000002,"bin_end":19958.578779,"count":0},{"bin_start":19958.578779,"bin_end":21984.47061,"count":1}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"age":"19","sex":"female","bmi":"27.9","children":"0","smoker":"yes","region":"southwest","charges":"16884.924","_deepnote_index_column":"0"},{"age":"18","sex":"male","bmi":"33.77","children":"1","smoker":"no","region":"southeast","charges":"1725.5523","_deepnote_index_column":"1"},{"age":"28","sex":"male","bmi":"33.0","children":"3","smoker":"no","region":"southeast","charges":"4449.462","_deepnote_index_column":"2"},{"age":"33","sex":"male","bmi":"22.705","children":"0","smoker":"no","region":"northwest","charges":"21984.47061","_deepnote_index_column":"3"},{"age":"32","sex":"male","bmi":"28.88","children":"0","smoker":"no","region":"northwest","charges":"3866.8552","_deepnote_index_column":"4"}]},"text/plain":"   age     sex     bmi  children smoker     region      charges\n0   19  female  27.900         0    yes  southwest  16884.92400\n1   18    male  33.770         1     no  southeast   1725.55230\n2   28    male  33.000         3     no  southeast   4449.46200\n3   33    male  22.705         0     no  northwest  21984.47061\n4   32    male  28.880         0     no  northwest   3866.85520","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>bmi</th>\n      <th>children</th>\n      <th>smoker</th>\n      <th>region</th>\n      <th>charges</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19</td>\n      <td>female</td>\n      <td>27.900</td>\n      <td>0</td>\n      <td>yes</td>\n      <td>southwest</td>\n      <td>16884.92400</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>male</td>\n      <td>33.770</td>\n      <td>1</td>\n      <td>no</td>\n      <td>southeast</td>\n      <td>1725.55230</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>male</td>\n      <td>33.000</td>\n      <td>3</td>\n      <td>no</td>\n      <td>southeast</td>\n      <td>4449.46200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>male</td>\n      <td>22.705</td>\n      <td>0</td>\n      <td>no</td>\n      <td>northwest</td>\n      <td>21984.47061</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32</td>\n      <td>male</td>\n      <td>28.880</td>\n      <td>0</td>\n      <td>no</td>\n      <td>northwest</td>\n      <td>3866.85520</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"data.dtypes","metadata":{"tags":[],"cell_id":"f95b2f00d4d24df8aaa4e1ef43398f68","source_hash":"ae3db336","execution_start":1669599758451,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"age           int64\nsex          object\nbmi         float64\nchildren      int64\nsmoker       object\nregion       object\ncharges     float64\ndtype: object"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"lb_encoder = LabelEncoder()\ndata.sex = lb_encoder.fit_transform(data.sex)\ndata.smoker = lb_encoder.fit_transform(data.smoker)\ndata.region = lb_encoder.fit_transform(data.region)","metadata":{"tags":[],"cell_id":"7d8821f280394ba09618d3a6093a83da","source_hash":"cbc5c46f","execution_start":1669599758458,"execution_millis":7,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data.head()","metadata":{"tags":[],"cell_id":"25bcbed001a94898b5370f6beb72d795","source_hash":"41313cfa","execution_start":1669599758467,"execution_millis":82,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":7,"row_count":5,"columns":[{"name":"age","dtype":"int64","stats":{"unique_count":5,"nan_count":0,"min":"18","max":"33","histogram":[{"bin_start":18,"bin_end":19.5,"count":2},{"bin_start":19.5,"bin_end":21,"count":0},{"bin_start":21,"bin_end":22.5,"count":0},{"bin_start":22.5,"bin_end":24,"count":0},{"bin_start":24,"bin_end":25.5,"count":0},{"bin_start":25.5,"bin_end":27,"count":0},{"bin_start":27,"bin_end":28.5,"count":1},{"bin_start":28.5,"bin_end":30,"count":0},{"bin_start":30,"bin_end":31.5,"count":0},{"bin_start":31.5,"bin_end":33,"count":2}]}},{"name":"sex","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":1},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":4}]}},{"name":"bmi","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"22.705","max":"33.77","histogram":[{"bin_start":22.705,"bin_end":23.8115,"count":1},{"bin_start":23.8115,"bin_end":24.918,"count":0},{"bin_start":24.918,"bin_end":26.0245,"count":0},{"bin_start":26.0245,"bin_end":27.131,"count":0},{"bin_start":27.131,"bin_end":28.2375,"count":1},{"bin_start":28.2375,"bin_end":29.344,"count":1},{"bin_start":29.344,"bin_end":30.4505,"count":0},{"bin_start":30.4505,"bin_end":31.557000000000002,"count":0},{"bin_start":31.557000000000002,"bin_end":32.6635,"count":0},{"bin_start":32.6635,"bin_end":33.77,"count":2}]}},{"name":"children","dtype":"int64","stats":{"unique_count":3,"nan_count":0,"min":"0","max":"3","histogram":[{"bin_start":0,"bin_end":0.3,"count":3},{"bin_start":0.3,"bin_end":0.6,"count":0},{"bin_start":0.6,"bin_end":0.8999999999999999,"count":0},{"bin_start":0.8999999999999999,"bin_end":1.2,"count":1},{"bin_start":1.2,"bin_end":1.5,"count":0},{"bin_start":1.5,"bin_end":1.7999999999999998,"count":0},{"bin_start":1.7999999999999998,"bin_end":2.1,"count":0},{"bin_start":2.1,"bin_end":2.4,"count":0},{"bin_start":2.4,"bin_end":2.6999999999999997,"count":0},{"bin_start":2.6999999999999997,"bin_end":3,"count":1}]}},{"name":"smoker","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":"0","max":"1","histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":1}]}},{"name":"region","dtype":"int64","stats":{"unique_count":3,"nan_count":0,"min":"1","max":"3","histogram":[{"bin_start":1,"bin_end":1.2,"count":2},{"bin_start":1.2,"bin_end":1.4,"count":0},{"bin_start":1.4,"bin_end":1.6,"count":0},{"bin_start":1.6,"bin_end":1.8,"count":0},{"bin_start":1.8,"bin_end":2,"count":0},{"bin_start":2,"bin_end":2.2,"count":2},{"bin_start":2.2,"bin_end":2.4000000000000004,"count":0},{"bin_start":2.4000000000000004,"bin_end":2.6,"count":0},{"bin_start":2.6,"bin_end":2.8,"count":0},{"bin_start":2.8,"bin_end":3,"count":1}]}},{"name":"charges","dtype":"float64","stats":{"unique_count":5,"nan_count":0,"min":"1725.5523","max":"21984.47061","histogram":[{"bin_start":1725.5523,"bin_end":3751.444131,"count":1},{"bin_start":3751.444131,"bin_end":5777.335962,"count":2},{"bin_start":5777.335962,"bin_end":7803.227793000001,"count":0},{"bin_start":7803.227793000001,"bin_end":9829.119624,"count":0},{"bin_start":9829.119624,"bin_end":11855.011455,"count":0},{"bin_start":11855.011455,"bin_end":13880.903286,"count":0},{"bin_start":13880.903286,"bin_end":15906.795117,"count":0},{"bin_start":15906.795117,"bin_end":17932.686948000002,"count":1},{"bin_start":17932.686948000002,"bin_end":19958.578779,"count":0},{"bin_start":19958.578779,"bin_end":21984.47061,"count":1}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"age":"19","sex":"0","bmi":"27.9","children":"0","smoker":"1","region":"3","charges":"16884.924","_deepnote_index_column":"0"},{"age":"18","sex":"1","bmi":"33.77","children":"1","smoker":"0","region":"2","charges":"1725.5523","_deepnote_index_column":"1"},{"age":"28","sex":"1","bmi":"33.0","children":"3","smoker":"0","region":"2","charges":"4449.462","_deepnote_index_column":"2"},{"age":"33","sex":"1","bmi":"22.705","children":"0","smoker":"0","region":"1","charges":"21984.47061","_deepnote_index_column":"3"},{"age":"32","sex":"1","bmi":"28.88","children":"0","smoker":"0","region":"1","charges":"3866.8552","_deepnote_index_column":"4"}]},"text/plain":"   age  sex     bmi  children  smoker  region      charges\n0   19    0  27.900         0       1       3  16884.92400\n1   18    1  33.770         1       0       2   1725.55230\n2   28    1  33.000         3       0       2   4449.46200\n3   33    1  22.705         0       0       1  21984.47061\n4   32    1  28.880         0       0       1   3866.85520","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>bmi</th>\n      <th>children</th>\n      <th>smoker</th>\n      <th>region</th>\n      <th>charges</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19</td>\n      <td>0</td>\n      <td>27.900</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>16884.92400</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>1</td>\n      <td>33.770</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1725.55230</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>1</td>\n      <td>33.000</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4449.46200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>1</td>\n      <td>22.705</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>21984.47061</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32</td>\n      <td>1</td>\n      <td>28.880</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3866.85520</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"X = data.iloc[:, :-1].values\ny = data.iloc[:, -1].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=2)\n\nreg = GradientBoostingRegressor() # modelo con hiperparametros por defecto\nreg.fit(X_train, y_train)\n\ny_pred = reg.predict(X_test)\n\nr2 = r2_score(y_test, y_pred)\nprint('R2:', r2)","metadata":{"tags":[],"cell_id":"42739f5f81cc47fc8910de989accecb5","source_hash":"454e8805","execution_start":1669599758548,"execution_millis":71,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"R2: 0.877581453601204\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Ahora que ya tenemos un modelo base con un R2 de 0.87, procedemos a utilizar las distintas técnicas para la optimización de hiperparámetros y ver que resultado obtenemos.","metadata":{"tags":[],"cell_id":"e4f79d4012454ba8ae633083705f8748","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":53,"fromCodePoint":43}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"## Búsqueda por grilla","metadata":{"tags":[],"cell_id":"8a57413dbc5e426ca24ee1a0acd13ef9","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"### Fundamento matemático","metadata":{"tags":[],"cell_id":"9ee8a1b395bf4a53a7c6e59363bf3e5f","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"markdown","source":"Los hiperparámetros de un modelo son valores que deben especificarse de antemano y generalmente no se obtienen de los datos por lo que deben ser seleccionados por el científico de datos. Es de gran importancia hacer una correcta selección dichos parámetros para evitar inconvenientes en el ajuste del modelo. Pueden elegirse entonces parámetros de diferentes tamaños, incorporarlos al modelo y seleccionar los de mejor rendimiento. ","metadata":{"tags":[],"cell_id":"310fea25-0938-4896-a9e4-c775a4c74cec","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"El método de búsqueda por grilla también conocido como búsqueda en cuadrícula o exhaustiva consiste en poner a prueba todas las posibles combinaciones de valores que se le proporcione en los parámetros. Esta prueba no se realiza de forma aleatoria sino en puntos del espacio repartidos en forma de cuadrícula. A partir de este algoritmo de optimización se seleccionan los mejores parámetros del espacio dado. Este método es conocido por su uso en aprendizaje de maquina para obtener los parámetros en los que el modelo ofrece la mejor precisión. Puede emplearse en diferentes problemas de optimización. Por ejemplo, la cantidad de árboles de decisión en el bosque aleatorio, la cantidad de nodos en cada capa de una red neuronal artificial o cantidad de capas ocultas etc.","metadata":{"tags":[],"cell_id":"1d1eaf08-2bb3-4b6e-8e92-e5480b45228d","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"\r","metadata":{"tags":[],"cell_id":"19cada9d-53a4-4097-a9ed-62bd5bc9cd23","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"En su implementación, el usuario lista los hiperparámetros y su producto cartesiano dado por permutaciones y combinaciones será su espacio. Así, cada dimensión será un hiperparámetro y cada punto representa la configuración al modelo. El algoritmo utiliza este espacio para entrenar el modelo y selecciona la combinación de parámetros con el error de validación más pequeño. Es decir que, sea $\\Omega^*$ el espacio dado de hiperparámetros $V=(v_1, v_2, \\ldots v_m)$. El método de grid seacrh define un vector de límites inferiores $a=(a_1, a_2, \\ldots a_m)$ y superiores $b=(b_1, b_2, \\ldots b_m)$ para cada componente del espacio $V$ y se toman $n$ puntos en cada intervalo $[a_i,b_i]$ con el mismo espacio entre cada punto. Esto dará como resultado $mn$ puntos de cuadrícula posibles para verificar en el modelo. Se calcula para cada uno y se eligen los hiperparámetros para los cuales el modelo tiene menor error.","metadata":{"tags":[],"cell_id":"5fbda2b6adca45729f1fd98e8378e4c3","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Si se consideran dos hiperparámetros, se tendría en este caso un espacio con dos dimensiones en el que se construye una cuadricula con los puntos a verificar de la siguiente manera\n\n<center><img src=\"GridSearch.png\" width=\"300\" height=\"300\"></center>\n\nNota. Imagen por Angélica Agudelo","metadata":{"tags":[],"cell_id":"57b5605882594d2ebbf78561ebe1bc5b","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Se puede importar GridSearchCV que nos permitirá la implementación del método búsqueda de cuadrícula mediante sklearn como sigue","metadata":{"tags":[],"cell_id":"d797652df9c04317aec15d4fa4b1238d","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{"tags":[],"cell_id":"6f4110b0be3741e2b139d8404fc66b52","source_hash":"385c9dff","execution_start":1669599758648,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### Ejemplos","metadata":{"tags":[],"cell_id":"fe4fd78bcaaa4638a76a40f99dd4e05c","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"markdown","source":"Definimos los parámetros del modelo que se desean obtener mediante la búsqueda de cuadrícula, para este caso se van a definir 7 parámetros de la siguiente manera","metadata":{"tags":[],"cell_id":"4397b296f9a94bc7a3a29b8af1ff4eeb","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"from sklearn.model_selection import ParameterGrid\nparam_grid = {'loss': ['squared_error', 'absolute_error', 'huber','quantile'],\n              'learning_rate': [0.05, 0.1, 0.15],\n              'n_estimators': [50,100,150],\n              'min_samples_split': [2, 3],\n              'min_samples_leaf': [1, 2],\n              'max_depth': [1, 2],\n              'max_features': ['sqrt', 'log2']}","metadata":{"tags":[],"cell_id":"3b9fff9b9bc2495a975982513f25f31e","source_hash":"d95945ba","execution_start":1669599758649,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Una vez definido el espacio de los parámetros realizamos la búsqueda de aquellos que se ajustan mejor al modelo","metadata":{"tags":[],"cell_id":"1e5ac7b5e1264d139257ab23909bd61f","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nGBR = GradientBoostingRegressor() \ngrid_GBR = GridSearchCV(GBR, param_grid, refit = True, verbose = 0,n_jobs=-1) ","metadata":{"tags":[],"cell_id":"5dd761fa28464436887008be3ab157f3","source_hash":"2c301221","execution_start":1669599758650,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":10},{"cell_type":"code","source":"X = data.iloc[:, :-1].values\nY = data.iloc[:, -1].values\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, shuffle=True, random_state=2)\n\ngrid_GBR.fit(X_train, y_train)","metadata":{"tags":[],"cell_id":"f97eacc787584a5c9e8a7f33e56cb2ad","source_hash":"c9161ea2","execution_start":1669599758650,"execution_millis":365427,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,\n             param_grid={'learning_rate': [0.05, 0.1, 0.15],\n                         'loss': ['squared_error', 'absolute_error', 'huber',\n                                  'quantile'],\n                         'max_depth': [1, 2], 'max_features': ['sqrt', 'log2'],\n                         'min_samples_leaf': [1, 2],\n                         'min_samples_split': [2, 3],\n                         'n_estimators': [50, 100, 150]})","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,\n             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1, 0.15],\n                         &#x27;loss&#x27;: [&#x27;squared_error&#x27;, &#x27;absolute_error&#x27;, &#x27;huber&#x27;,\n                                  &#x27;quantile&#x27;],\n                         &#x27;max_depth&#x27;: [1, 2], &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n                         &#x27;min_samples_leaf&#x27;: [1, 2],\n                         &#x27;min_samples_split&#x27;: [2, 3],\n                         &#x27;n_estimators&#x27;: [50, 100, 150]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,\n             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1, 0.15],\n                         &#x27;loss&#x27;: [&#x27;squared_error&#x27;, &#x27;absolute_error&#x27;, &#x27;huber&#x27;,\n                                  &#x27;quantile&#x27;],\n                         &#x27;max_depth&#x27;: [1, 2], &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n                         &#x27;min_samples_leaf&#x27;: [1, 2],\n                         &#x27;min_samples_split&#x27;: [2, 3],\n                         &#x27;n_estimators&#x27;: [50, 100, 150]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"Encontramos los parámetros y con estos podemos calcular el coeficiente de determinación del modelo construido con ellos","metadata":{"tags":[],"cell_id":"8a873c35f45541098343e557b896b594","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"print(\" Resulatdos Grid Search \" )\nprint(\"\\n Los mejores parámetros encontrados en la búsqueda son:\\n\",grid_GBR.best_params_)\n\ny_pred= grid_GBR.predict(X_test)\nr2=r2_score(y_test,y_pred)\nprint(\"\\n El coeficiente de determinación del modelo es:\\n\",r2)","metadata":{"tags":[],"cell_id":"04ab72ada6d1480993c6ea088c84f650","source_hash":"db31fbd9","execution_start":1669600124075,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":" Resulatdos Grid Search \n\n Los mejores parámetros encontrados en la búsqueda son:\n {'learning_rate': 0.15, 'loss': 'huber', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 150}\n\n El coeficiente de determinación del modelo es:\n 0.8650136879445166\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Nótese que aunque se tomaron en cuenta los parámetros escogidos en la búsqueda de grilla el coeficiente de determinación disminuyó pues en la búsqueda no se están considerando todos los posibles valores de hiperparámetros por el costo computacional","metadata":{"tags":[],"cell_id":"18e0340280c24dbaa793d538d1e5d826","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"","metadata":{"tags":[],"cell_id":"5359a2ba5dce4441965b82d27228bae5","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"## Búsqueda aleatoria","metadata":{"tags":[],"cell_id":"d7a5706e7431436381baead69f28c46c","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"### Fundamento matemático","metadata":{"tags":[],"cell_id":"93f5f71f3a87465b8bedbe15c2c906cd","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"markdown","source":"La búsqueda aleatoria (random search) hace parte de los métodos de optimización directa al no requerir de la optimización del gradiente. Este método como su nombre lo dice, hace una búsqueda aleatoria sobre los parámetros, donde se sacan muestras independientes a partir de una distribución uniforme sobre los posibles valores para los parámetros. Las muestras se toman sobre el mismo espacio de configuración que se abarcaría con la búsqueda por grilla.","metadata":{"tags":[],"cell_id":"147d3d354b2e4c18b37fecae4384a3d3","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"<center><img src=\"RS.png\" width=\"400\"></center>","metadata":{"tags":[],"cell_id":"72d28cccb43e4986a1e9b715162ad06b","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"\r\nNota. Adaptado de Randomized Search [Imagen], por Maël Fabien, 2020, Github (https://maelfabien.github.io/machinelearning/Explorium4/#what-is-hyperparameter-optimization).","metadata":{"tags":[],"cell_id":"594f9d87-ffc4-4bbb-966e-5c2f7647468a","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":6,"fromCodePoint":2},{"type":"marks","marks":{"italic":true},"toCodePoint":37,"fromCodePoint":20},{"url":"https://maelfabien.github.io/machinelearning/Explorium4/#what-is-hyperparameter-optimization","type":"link","ranges":[],"toCodePoint":171,"fromCodePoint":79}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Según wikipedia el nombre de \"búsqueda aleatoria\" se atribuye a Rastrigin quien hizo una presentación temprana del método junto con un algoritmo matemático básico. Este funciona moviéndose iterativamente a mejores posiciones en el espacio de búsqueda, que se muestrean desde una hiperesfera que rodea la posición actual. ","metadata":{"tags":[],"cell_id":"38dc5c10-598b-4274-95e1-dd7013df129b","is_collapsed":false,"formattedRanges":[{"url":"https://en.wikipedia.org/wiki/Random_search","type":"link","ranges":[],"toCodePoint":15,"fromCodePoint":6}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Es decir, sea $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$ la función a ser minimizada y sea $x \\in \\mathbb{R}^n$ un valor candidato a ser solución en el espacio de búsqueda entonces se inicia $x$ en una posición aleatoria en el espacio de búsqueda y hasta que se cumplan un número de iteraciones o se cumpla un criterio de finalización, se muestrea una nueva posición $y$ de la hiperesfera de un radio dado que rodea la posición actual de $x$ y si $f(y) < f(x)$ entonces la nueva posición de $x$ es la de $y$ y cuando se cumple el criterio de terminación $x$ ocupa la mejor posición encontrada.\n\nA diferencia de este algotitmo matemático básico con el que se inicio la búsqueda aleatoria, en el método utilizado para la optimización de hiperparámetros en la selección de modelos, la nueva posición $y$ de $x$ se muestrea agregando un vector aleatorio con distribución normal a la actual posición de $x$. \n\nA comparación de la búsqueda en cuadrícula, con la búsqueda aleatoria no se pierde la eficiencia al bajar la dimensionalidad cuando se tienen muchos parámetros. Por ejemplo, si tengo una función $f$ de dos variables y ésta se puede aproximar a una función con una sola variable ($f(x,y) \\approx g(x)$), entonces la función $f$ tiene una baja dimensionalidad efectiva.\n\nA continuación, se muestra la diferencia entre la búsqueda de cuadrícula y la aleatoria al optimizar la función $f(x, y) = g(x) + h(y) \\approx g(x)$ con baja dimensionalidad efectiva, donde se observa como con la búsqueda aleatoria si se abarcan todos los distintos valores de $g$ para los parámetros.\n<center><img src=\"GS_vs_RS.png\" width=\"800\"></center>","metadata":{"tags":[],"cell_id":"3e7d2c657304431d8047520954b1d9ff","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Nota. Adaptado de Grid and random search [Imagen], por Bergstra, J. & Bengio, Y., 2012, Journal of Machine Learning Research (https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf).","metadata":{"tags":[],"cell_id":"76df455ec8b24482af7b9201075a90a6","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":4,"fromCodePoint":0},{"type":"marks","marks":{"italic":true},"toCodePoint":40,"fromCodePoint":18},{"url":"https://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf","type":"link","ranges":[],"toCodePoint":190,"fromCodePoint":126}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Matemáticamente, para un número dado de iteraciones $N$, en un conjunto $V$ de hiperparámetros. Se explora $N$ diferentes valores para cada hiperparámetro mientras en la búsqueda en cuadrícula se exploravan $N^{\\frac{1}{V}}$ valores para cada hiperparámetro.","metadata":{"tags":[],"cell_id":"a5a62051e2e1420c93739bcaa1e1b088","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Con la librería RandomizedSearchCV  del paquete sklearn se puede implementar en Python la búsqueda aleatoria. Para ello, hay que escribir el siguiente comando","metadata":{"tags":[],"cell_id":"c4a6f1d429354af2acea4d4d6871ddb9","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true,"italic":true},"toCodePoint":34,"fromCodePoint":16},{"type":"marks","marks":{"bold":true},"toCodePoint":56,"fromCodePoint":48}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV","metadata":{"tags":[],"cell_id":"5b739c616d794dd8881641f638062fa0","source_hash":"f576e39e","execution_start":1669600124076,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### Ejemplos","metadata":{"tags":[],"cell_id":"bd84149bc9dd4cc49b8d3915e58d0b74","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"markdown","source":"Definimos los posibles hiperparámetros del modelo y con la función RandomizedSearchCV encontramos cuales se ajustan mejor al modelo.","metadata":{"tags":[],"cell_id":"37eacfd3b3c84fab841dbc91a2266d9f","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":86,"fromCodePoint":67}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"hyperparameters = dict(loss = ['squared_error', 'absolute_error', 'huber', 'quantile'],\n                       learning_rate = [0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2],\n                       min_samples_split = [2, 3, 4, 5],\n                       min_samples_leaf = [1, 2, 3, 4],\n                       max_depth = [1, 2, 3, 4, 5, 6, 7],\n                       max_features = ['sqrt', 'log2'],\n                       n_estimators = [20, 40, 60, 80, 100, 120, 140, 160, 180, 200])\n\nclf = RandomizedSearchCV(reg, hyperparameters, random_state=0)\n\nX = data.iloc[:, :-1].values\ny = data.iloc[:, -1].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n\nsearch = clf.fit(X_train, y_train)\nparameters=search.best_params_\nprint('Mejores parámetros:', parameters)","metadata":{"tags":[],"cell_id":"385502e12b8348488e4809b09a4f3b93","source_hash":"6b703569","execution_start":1669600124077,"execution_millis":19328,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Mejores parámetros: {'n_estimators': 180, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 4, 'loss': 'huber', 'learning_rate': 0.2}\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Posteriormente, ajustamos el modelo con esos hiperparámetros y calculamos el coeficiente de determinación R2.","metadata":{"tags":[],"cell_id":"700e05d2341247ac89202148d22ae66d","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"reg = GradientBoostingRegressor(loss=parameters['loss'], \n                                learning_rate = parameters['learning_rate'], \n                                min_samples_split = parameters['min_samples_split'], \n                                min_samples_leaf = parameters['min_samples_leaf'], \n                                max_depth = parameters['max_depth'],\n                                max_features = parameters['max_features'],\n                                n_estimators = parameters['n_estimators'])\nreg.fit(X_train, y_train)\n\ny_pred = reg.predict(X_test)\n\nr2 = r2_score(y_test, y_pred)\nprint('R2:', r2)","metadata":{"tags":[],"cell_id":"acd27a8bc91b48fcb229b0a9b08dcee1","source_hash":"1f63989c","execution_start":1669600142849,"execution_millis":1057,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"R2: 0.7952619140358745\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Según el coeficiente de determinación se podría decir que para el modelo inicial los hiperparámetros escogidos por este método no son los mejores, dado que el coeficiente del modelo base es mayor.","metadata":{"tags":[],"cell_id":"d3897acfc8ca4dcdb0ded243ed7b1410","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"## Optimización bayesiana","metadata":{"tags":[],"cell_id":"011de5648076406a870e09392ba74666","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"### Fundamento matemático","metadata":{"tags":[],"cell_id":"f89c5d0f789e4ae5994896cd2193e6bd","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"markdown","source":"Con este método de optimización de hiperparámetros es posible reducir dramáticamente el costo computacional de encontrar el conjunto de hiperparámetros ideal para nuestro modelo dentro de nuestro espacio de búsqueda, y a la vez no lidia con el problema que presentan la búsqueda de grilla o la búsqueda aleatoria, que hace que el espacio de búsqueda sea mucho más reducido debido al costo computacional, y además nunca es garantizado que con la búsqueda aleatoria podremos obtener los hiperparámetros ideales.","metadata":{"tags":[],"cell_id":"93fadc66-2324-4612-9f45-8fc2a5357ff7","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"En la optimización de hiperparámetros usando optimización bayesiana, se lleva un registro de todas las evaluaciones pasadas de posibles hiperparámetros, mediante un modelo probabilístico que mapea hiperparámetros a la probabilidad de tener cierto puntaje en la función objetivo dados dichos hiperparámetros. Este modelo probabilístico esta definido como\n\n$$\np(score \\ | \\ hyperparameters)\n$$\n\nEste modelo es llamado en la literatura como un \"sustituto\" de la función objetivo que es la que queremos optimizar. Esta aproximación es un modelo probabilístico que dado un conjunto de hiperparámetros, se evalúa la función objetivo en este conjunto y se retorna un score que es usado para actualizar la distribución del modelo probabilístico, entonces con cada iteración, este modelo probabilístico se vuelve un predictor mas robusto de scores. \nLa distribución se actualiza usando el teorema de Bayes, ya que se calcula de la siguiente forma:\n$$\np(score \\ | \\ hyperparameters) = \\frac{p(hyperparameters \\ | \\ score)\\cdot p(score)}{p(hyperparameters)}\n$$\ndonde\n$$\np(hyperparameters \\ | \\ score) = \n\\begin{cases}\nl(x), \\ if \\text{ -score} < \\text{ -score threshold} \\\\\ng(x), \\ if \\text{ -score} \\geq \\text{ -score threshold} \n\\end{cases}\n$$\nCada vez que un conjunto de hiperparametros se evalúa en la función objetivo, se obtiene una mezcla gaussiana $l(x)$ ó $g(x)$ que depende del score obtenido. Este método es eficiente porque el conjunto de hiperparámetros que elige en cada iteración lo hace de una manera informada, guiandose por el modelo probabilístico.\n\nPor lo anterior, en cada iteración el modelo sustituto se va ajustando más a la función objetivo, veamos que en una primera iteración, el modelo sustituto (linea negra continua) y la función objetivo (linea roja punteada) se ven así:\n\n<center><img src=\"image-20220926-214500.png\"></center>\n\nCada punto negro es una evaluación del modelo sustituto, y luego de 8 evaluaciones el modelo sustituto luce de la siguiente forma:\n\n<center><img src=\"image-20220926-214733.png\"></center>","metadata":{"tags":[],"cell_id":"8f669d8d4ba44529ad07bdcdd477b4a1","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Nota. Adaptado de A Conceptual Explanation of Bayesian Model Based Hyperparameter Optimization for Machine Learning (https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f)","metadata":{"tags":[],"cell_id":"95f953d513dd4189a5a7f82d5da876e2","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"italic":true},"toCodePoint":4,"fromCodePoint":0},{"type":"marks","marks":{"italic":true},"toCodePoint":116,"fromCodePoint":18},{"url":"https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f","type":"link","ranges":[],"toCodePoint":258,"fromCodePoint":117}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Este modelo sustituto es también lo que se conoce como una distribución de probabilidad a priori, y el modelo que resulta despues de realizar varias evaluaciones en la función objetivo y formar el modelo sustituto, es lo que se conoce como probabilidad a posteriori sobre la función objetivo.","metadata":{"tags":[],"cell_id":"6f5726da-2882-48de-a467-8a7919d687f3","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":96,"fromCodePoint":59},{"type":"marks","marks":{"bold":true},"toCodePoint":266,"fromCodePoint":240}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Hay distintas librerías para optimización bayesiana de hiperparámetros, a continuación mostramos la más utilizada y como se usa en Python","metadata":{"tags":[],"cell_id":"29bb6a35d0f54d77b01dd72cbcd529e5","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"import optuna","metadata":{"tags":[],"cell_id":"92b4427fec2e436c976edb93ac8d9b5c","source_hash":"28929651","execution_start":1669600143908,"execution_millis":576,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/shared-libs/python3.9/py/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"### Ejemplos","metadata":{"tags":[],"cell_id":"65c016de7d56418e802be8f7f0a9c050","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"markdown","source":"A continuación vamos a dar un ejemplo donde usamos la librería optuna que es la más popular entre las demás.","metadata":{"tags":[],"cell_id":"6a00c3ea85bf4c3f886562b765d84f22","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":69,"fromCodePoint":63}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Definimos la función objetivo, como esta función retorna el coeficiente de determinación R2 y entre más alto mejor, entonces esta función objetivo es una función que vamos a maximizar.","metadata":{"tags":[],"cell_id":"7c286e63fd4b4e0ca3703f049eb56ba4","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":184,"fromCodePoint":174}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"def objective(trial):\n    # set hyperparameters\n    _loss = trial.suggest_categorical('loss', {'squared_error', 'absolute_error', 'huber'})\n    _learning_rate = trial.suggest_float('learning_rate', low = 0.025, high = 0.2, step = 0.025)\n    _min_samples_split = trial.suggest_int('min_samples_split', low = 2, high = 5, step = 1)\n    _min_samples_leaf = trial.suggest_int('min_samples_leaf', low = 1, high = 4, step = 1)\n    _max_depth = trial.suggest_int('max_depth', low = 1, high = 7, step = 1)\n    _max_features = trial.suggest_categorical('max_features', {'sqrt', 'log2'})\n    _n_estimators = trial.suggest_int('n_estimators', low = 20, high = 200, step = 20)\n\n    X = data.iloc[:, :-1].values\n    y = data.iloc[:, -1].values\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n\n    reg = GradientBoostingRegressor(loss=_loss, \n                                    learning_rate = _learning_rate, \n                                    min_samples_split = _min_samples_split, \n                                    min_samples_leaf = _min_samples_leaf, \n                                    max_depth = _max_depth,\n                                    max_features = _max_features,\n                                    n_estimators = _n_estimators)\n    reg.fit(X_train, y_train)\n\n    y_pred = reg.predict(X_test)\n\n    r2 = r2_score(y_test, y_pred)\n\n    return r2","metadata":{"tags":[],"cell_id":"17d068a66b404fbb94e18fc4b97cc9e6","source_hash":"38ac5819","execution_start":1669600144489,"execution_millis":3,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"Creamos un objeto de tipo `optuna.Study` donde especificamos que estamos ante un problema de maximización, luego ejecutas el método `study.optimize` donde especificamos la función objetivo, el número de intentos como 100 y el número de cores a utilizar durante la optimización.","metadata":{"tags":[],"cell_id":"8818a7cca6994b8d8d5dbfc0ca6c3fd2","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100, n_jobs=-1)","metadata":{"tags":[],"cell_id":"491669e34dad4617a42f958d92ea5925","source_hash":"c3b17cc","execution_start":1669600144494,"execution_millis":160379,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-11-28 01:49:04,493]\u001b[0m A new study created in memory with name: no-name-37e52e3c-074c-448a-afc2-2e1d28d1da99\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:04,718]\u001b[0m Trial 3 finished with value: 0.7980653551924303 and parameters: {'loss': 'squared_error', 'learning_rate': 0.07500000000000001, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 20}. Best is trial 3 with value: 0.7980653551924303.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:05,140]\u001b[0m Trial 4 finished with value: 0.7915604189213935 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.2, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 20}. Best is trial 3 with value: 0.7980653551924303.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:05,148]\u001b[0m Trial 0 finished with value: 0.7493286815828024 and parameters: {'loss': 'squared_error', 'learning_rate': 0.07500000000000001, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 1, 'max_features': 'log2', 'n_estimators': 200}. Best is trial 3 with value: 0.7980653551924303.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:05,757]\u001b[0m Trial 6 finished with value: 0.741460765728745 and parameters: {'loss': 'squared_error', 'learning_rate': 0.15, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 1, 'max_features': 'log2', 'n_estimators': 140}. Best is trial 3 with value: 0.7980653551924303.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:07,434]\u001b[0m Trial 2 finished with value: 0.8238759408121616 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.2, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 180}. Best is trial 2 with value: 0.8238759408121616.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:08,127]\u001b[0m Trial 1 finished with value: 0.7263873178948952 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 1, 'max_features': 'sqrt', 'n_estimators': 200}. Best is trial 2 with value: 0.8238759408121616.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:08,939]\u001b[0m Trial 9 finished with value: 0.8412580438594734 and parameters: {'loss': 'squared_error', 'learning_rate': 0.05, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 180}. Best is trial 9 with value: 0.8412580438594734.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:09,377]\u001b[0m Trial 8 finished with value: 0.7813009064815581 and parameters: {'loss': 'squared_error', 'learning_rate': 0.17500000000000002, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 200}. Best is trial 9 with value: 0.8412580438594734.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:10,036]\u001b[0m Trial 11 finished with value: 0.8276503875188861 and parameters: {'loss': 'squared_error', 'learning_rate': 0.1, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 120}. Best is trial 9 with value: 0.8412580438594734.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:10,709]\u001b[0m Trial 7 finished with value: 0.8773471676053491 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}. Best is trial 7 with value: 0.8773471676053491.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:11,225]\u001b[0m Trial 10 finished with value: 0.6491722980235829 and parameters: {'loss': 'huber', 'learning_rate': 0.025, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 40}. Best is trial 7 with value: 0.8773471676053491.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:15,297]\u001b[0m Trial 13 finished with value: 0.8373335790153529 and parameters: {'loss': 'huber', 'learning_rate': 0.15, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 80}. Best is trial 7 with value: 0.8773471676053491.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:16,444]\u001b[0m Trial 14 finished with value: 0.7766098254135674 and parameters: {'loss': 'huber', 'learning_rate': 0.025, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 80}. Best is trial 7 with value: 0.8773471676053491.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:18,946]\u001b[0m Trial 5 finished with value: 0.8728715220425727 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.17500000000000002, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 100}. Best is trial 7 with value: 0.8773471676053491.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:22,518]\u001b[0m Trial 16 finished with value: 0.8814674209484139 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 160}. Best is trial 16 with value: 0.8814674209484139.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:22,930]\u001b[0m Trial 15 finished with value: 0.8229356357625557 and parameters: {'loss': 'huber', 'learning_rate': 0.025, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 80}. Best is trial 16 with value: 0.8814674209484139.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:28,125]\u001b[0m Trial 18 finished with value: 0.863795830161098 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 140}. Best is trial 16 with value: 0.8814674209484139.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:28,362]\u001b[0m Trial 19 finished with value: 0.8855262807517064 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 140}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:30,323]\u001b[0m Trial 17 finished with value: 0.8576214967512338 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.15, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 80}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:34,360]\u001b[0m Trial 20 finished with value: 0.8665583457232433 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 160}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:34,496]\u001b[0m Trial 21 finished with value: 0.8481598321697588 and parameters: {'loss': 'huber', 'learning_rate': 0.15, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 160}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:35,295]\u001b[0m Trial 12 finished with value: 0.8346302518503315 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.17500000000000002, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:36,764]\u001b[0m Trial 22 finished with value: 0.8336317489746803 and parameters: {'loss': 'huber', 'learning_rate': 0.07500000000000001, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 160}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:40,223]\u001b[0m Trial 23 finished with value: 0.8623103042578181 and parameters: {'loss': 'huber', 'learning_rate': 0.07500000000000001, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 140}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:45,069]\u001b[0m Trial 24 finished with value: 0.8331464096220231 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 120}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:46,250]\u001b[0m Trial 25 finished with value: 0.8544553577243013 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 120}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:47,408]\u001b[0m Trial 26 finished with value: 0.8707993306135148 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 120}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:50,825]\u001b[0m Trial 27 finished with value: 0.8394942318462713 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 120}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:50,857]\u001b[0m Trial 28 finished with value: 0.8741981406501975 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:52,051]\u001b[0m Trial 29 finished with value: 0.8274806526995739 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:53,234]\u001b[0m Trial 31 finished with value: 0.8416689554464303 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 60}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:53,318]\u001b[0m Trial 30 finished with value: 0.8676554560658046 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:57,538]\u001b[0m Trial 32 finished with value: 0.878966729690618 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 180}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:58,760]\u001b[0m Trial 33 finished with value: 0.8652931257947215 and parameters: {'loss': 'huber', 'learning_rate': 0.15, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 180}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:49:58,768]\u001b[0m Trial 34 finished with value: 0.8561675392834343 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:00,544]\u001b[0m Trial 35 finished with value: 0.8506632185597192 and parameters: {'loss': 'huber', 'learning_rate': 0.07500000000000001, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 140}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:01,555]\u001b[0m Trial 36 finished with value: 0.8695678230351321 and parameters: {'loss': 'huber', 'learning_rate': 0.07500000000000001, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 180}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:02,355]\u001b[0m Trial 39 finished with value: 0.6668759208826973 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.05, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 1, 'max_features': 'log2', 'n_estimators': 180}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:02,810]\u001b[0m Trial 38 finished with value: 0.8186209059269973 and parameters: {'loss': 'huber', 'learning_rate': 0.05, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 160}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:03,009]\u001b[0m Trial 37 finished with value: 0.8538873864715875 and parameters: {'loss': 'huber', 'learning_rate': 0.07500000000000001, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 180}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:03,226]\u001b[0m Trial 41 finished with value: 0.8523316685928977 and parameters: {'loss': 'squared_error', 'learning_rate': 0.125, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 160}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:03,424]\u001b[0m Trial 40 finished with value: 0.6670220753209722 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.05, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 1, 'max_features': 'log2', 'n_estimators': 160}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:03,838]\u001b[0m Trial 43 finished with value: 0.7849661582599461 and parameters: {'loss': 'squared_error', 'learning_rate': 0.17500000000000002, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 1, 'max_features': 'sqrt', 'n_estimators': 200}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:04,162]\u001b[0m Trial 42 finished with value: 0.8310140092446364 and parameters: {'loss': 'squared_error', 'learning_rate': 0.15, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 200}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:08,066]\u001b[0m Trial 44 finished with value: 0.8602549302454102 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 140}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:08,301]\u001b[0m Trial 45 finished with value: 0.854524472450268 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 140}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:08,758]\u001b[0m Trial 46 finished with value: 0.8623973325829777 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 140}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:09,118]\u001b[0m Trial 47 finished with value: 0.8674779530399703 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 140}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:11,653]\u001b[0m Trial 49 finished with value: 0.8743396678470037 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 60}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:11,828]\u001b[0m Trial 51 finished with value: 0.8032133502591787 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.125, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 60}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:12,127]\u001b[0m Trial 50 finished with value: 0.8210984861742474 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 60}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:13,312]\u001b[0m Trial 54 finished with value: 0.8139543635448278 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 20}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:13,682]\u001b[0m Trial 52 finished with value: 0.8404214074336622 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.125, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 40}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:14,260]\u001b[0m Trial 48 finished with value: 0.8737508943861452 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:16,048]\u001b[0m Trial 55 finished with value: 0.8428626594004577 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 40}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:17,015]\u001b[0m Trial 53 finished with value: 0.8415544236901401 and parameters: {'loss': 'huber', 'learning_rate': 0.15, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 40}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:23,069]\u001b[0m Trial 58 finished with value: 0.8260551952354923 and parameters: {'loss': 'huber', 'learning_rate': 0.15, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 80}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:23,653]\u001b[0m Trial 56 finished with value: 0.8573046484346531 and parameters: {'loss': 'huber', 'learning_rate': 0.15, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 80}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:23,874]\u001b[0m Trial 59 finished with value: 0.851141961692387 and parameters: {'loss': 'huber', 'learning_rate': 0.2, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 80}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:24,015]\u001b[0m Trial 57 finished with value: 0.8651170528000387 and parameters: {'loss': 'huber', 'learning_rate': 0.15, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 80}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:24,858]\u001b[0m Trial 63 finished with value: 0.884570951142419 and parameters: {'loss': 'squared_error', 'learning_rate': 0.125, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 120}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:24,937]\u001b[0m Trial 62 finished with value: 0.8572894377257294 and parameters: {'loss': 'squared_error', 'learning_rate': 0.125, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 120}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:25,785]\u001b[0m Trial 65 finished with value: 0.8574708758266734 and parameters: {'loss': 'squared_error', 'learning_rate': 0.125, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 120}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:25,860]\u001b[0m Trial 64 finished with value: 0.8537144114940209 and parameters: {'loss': 'squared_error', 'learning_rate': 0.125, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 120}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:26,401]\u001b[0m Trial 66 finished with value: 0.8154404958996089 and parameters: {'loss': 'squared_error', 'learning_rate': 0.1, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:26,548]\u001b[0m Trial 67 finished with value: 0.8655529028033925 and parameters: {'loss': 'squared_error', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 2, 'max_features': 'sqrt', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:27,398]\u001b[0m Trial 68 finished with value: 0.838132958302507 and parameters: {'loss': 'squared_error', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:31,028]\u001b[0m Trial 60 finished with value: 0.8432813114124562 and parameters: {'loss': 'huber', 'learning_rate': 0.07500000000000001, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:32,130]\u001b[0m Trial 61 finished with value: 0.8668067861187739 and parameters: {'loss': 'huber', 'learning_rate': 0.2, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 120}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:33,511]\u001b[0m Trial 70 finished with value: 0.8111664638818172 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 160}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:35,324]\u001b[0m Trial 69 finished with value: 0.8500192116689277 and parameters: {'loss': 'huber', 'learning_rate': 0.07500000000000001, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 160}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:37,249]\u001b[0m Trial 71 finished with value: 0.8421506329561229 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 160}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:38,244]\u001b[0m Trial 72 finished with value: 0.8696971844479234 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 160}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:38,846]\u001b[0m Trial 74 finished with value: 0.8526758275485699 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 60}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:41,628]\u001b[0m Trial 73 finished with value: 0.8477268944776046 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 140}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:43,120]\u001b[0m Trial 75 finished with value: 0.8577287424983863 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:44,315]\u001b[0m Trial 76 finished with value: 0.8561808279779943 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:48,896]\u001b[0m Trial 77 finished with value: 0.8609439562109007 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 180}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:51,308]\u001b[0m Trial 80 finished with value: 0.8523696005858019 and parameters: {'loss': 'huber', 'learning_rate': 0.07500000000000001, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 180}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:51,609]\u001b[0m Trial 78 finished with value: 0.8606903550006624 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 180}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:52,596]\u001b[0m Trial 81 finished with value: 0.7977049262678546 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.07500000000000001, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 120}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:53,137]\u001b[0m Trial 79 finished with value: 0.8527138347995598 and parameters: {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 180}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:55,002]\u001b[0m Trial 82 finished with value: 0.8216032045535433 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.125, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 120}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:50:55,426]\u001b[0m Trial 83 finished with value: 0.813752495448878 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.125, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 3, 'max_features': 'log2', 'n_estimators': 120}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:02,226]\u001b[0m Trial 87 finished with value: 0.8355014976383294 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.17500000000000002, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 5, 'max_features': 'sqrt', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:04,151]\u001b[0m Trial 88 finished with value: 0.8423937065130753 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.17500000000000002, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 80}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:04,540]\u001b[0m Trial 84 finished with value: 0.8509834953743608 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.17500000000000002, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 80}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:05,926]\u001b[0m Trial 85 finished with value: 0.8852547910999377 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.125, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 80}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:09,497]\u001b[0m Trial 86 finished with value: 0.876250061588018 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.17500000000000002, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:09,705]\u001b[0m Trial 91 finished with value: 0.841098755128579 and parameters: {'loss': 'huber', 'learning_rate': 0.125, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 60}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:13,256]\u001b[0m Trial 90 finished with value: 0.8500853349564385 and parameters: {'loss': 'huber', 'learning_rate': 0.15, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 4, 'max_features': 'log2', 'n_estimators': 140}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:18,996]\u001b[0m Trial 93 finished with value: 0.8671167472791774 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.15, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 60}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:19,044]\u001b[0m Trial 92 finished with value: 0.8407707987364769 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.15, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 60}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:25,407]\u001b[0m Trial 89 finished with value: 0.8848017755774821 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.1, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 140}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:29,061]\u001b[0m Trial 94 finished with value: 0.8263188845668915 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.15, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:34,722]\u001b[0m Trial 95 finished with value: 0.8035760518673655 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.1, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:35,919]\u001b[0m Trial 96 finished with value: 0.8167886773302769 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.1, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 100}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:43,768]\u001b[0m Trial 97 finished with value: 0.8731647412520496 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.1, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 140}. Best is trial 19 with value: 0.8855262807517064.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:44,729]\u001b[0m Trial 99 finished with value: 0.8902168656116525 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.125, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 140}. Best is trial 99 with value: 0.8902168656116525.\u001b[0m\n\u001b[32m[I 2022-11-28 01:51:44,865]\u001b[0m Trial 98 finished with value: 0.853925197840823 and parameters: {'loss': 'absolute_error', 'learning_rate': 0.1, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 7, 'max_features': 'log2', 'n_estimators': 140}. Best is trial 99 with value: 0.8902168656116525.\u001b[0m\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"Posterior a los intentos de maximizar el coeficiente de determinación, procedemos a mostrar el mejor conjunto de hiperparámetros y el coeficiente de determinación obtenido de este conjunto de hiperparámetros.","metadata":{"tags":[],"cell_id":"d149e10c7367427c8d8f21a722dae45e","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"print('Mejor conjunto de hiperparametros:\\n' + str(study.best_params))\nprint('Mejor coeficiente de determinación:', study.best_value)","metadata":{"tags":[],"cell_id":"84f8643754d348bdb3e2481f17c4e0ab","source_hash":"85b19ac8","execution_start":1669600304875,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Mejor conjunto de hiperparametros:\n{'loss': 'absolute_error', 'learning_rate': 0.125, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 140}\nMejor coeficiente de determinación: 0.8902168656116525\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"Con el método en cuestión obtenemos un mejor coeficiente de determinación, entonces este método resulta ser efectivo.","metadata":{"tags":[],"cell_id":"e79a080117314c10bc4ced5aaeb7ecf0","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"## Ejercicio","metadata":{"tags":[],"cell_id":"ce64bb60908b46959a36862481f75e4a","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"El ejercicio propuesto para el lector es ajustar un árbol de decisión (DecisionTreeRegressor) de scikit-learn al conjunto de datos usado en esta exposición, y utilizar el método de optimización bayesiana para la optimización de hiperparámetros. El objetivo de este ejercicio es obtener un coeficiente de determinación (R2) mayor a 0.89 que fue el último obtenido con el método de optimización bayesiana.","metadata":{"tags":[],"cell_id":"fa6a6d470e0241f9b576d2c351d680eb","is_collapsed":false,"formattedRanges":[{"url":"https://en.wikipedia.org/wiki/Coefficient_of_determination","type":"link","ranges":[],"toCodePoint":322,"fromCodePoint":289},{"type":"marks","marks":{"bold":true},"toCodePoint":323,"fromCodePoint":322}],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=006e66de-9f6a-4c40-bebc-c7a7dc0f0ecd' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"756a25c0db654557a6393692e7e232fa","deepnote_persisted_session":{"createdAt":"2022-11-28T02:16:14.300Z"},"deepnote_execution_queue":[]}}
