{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#F72585\"><center>Análisis exploratorio de Modelos Bayesianos</center></span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>(TFP)<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Introducción</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se introducen los elementos esenciales del análisis exploratorio de  Modelos Bayesianos. Usaremos la librería [Arviz](https://arviz-devs.github.io/arviz/) que es una libería desarrollada para hacer estos análisis en Python. \n",
    "\n",
    "En particular, Arviz puede trabajar con las salidas de TFP.\n",
    "\n",
    "En este cuaderno usamos el ejemplo de 8 escuelas (eight schools) que utilizamos en el [primer ejemplo de Stan en este curso](Stan_Ejemplo_1_eight_schools.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">El modelo estadístico para ete tutorial</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos observaciones $[y_n |x_n], n=1,\\ldots,N$, y asumamos el modelo Bayesiano. \n",
    "\n",
    "**Modelo con efectos aleatorios**\n",
    "\n",
    "- Estima los hiperparámetros $\\mu$ and $\\tau$\n",
    "- Predice los efectos aleatorios $\\eta_i$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y_i &\\sim \\mathcal{N}(\\theta_i,\\sigma_i^2), \\text{ known } \\sigma_i^2\\\\\n",
    "\\theta_i & = \\mu + \\tau \\times \\eta_i \\\\\n",
    "\\eta_i &\\sim \\mathcal{N}(0, 1)\\\\\n",
    "\\mu &\\sim \\mathcal{N}(0, 5)\\\\\n",
    "\\tau &\\sim \\mathcal{Cauchy}(0, 5)1_{\\tau>0.0}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Los datos</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos corresponden a la estimación (estandarizada) de un puntaje realizada en las ocho escuelas observadas.\n",
    "\n",
    "\n",
    "```{table}\n",
    "|School |Estim. Treatment Effect | Estim. Stand. Error |\n",
    "|---|---|---|\n",
    "|A |28| 15|\n",
    "|B |8 |10|\n",
    "|C| -3| 16|\n",
    "|D| 7| 11|\n",
    "|E| -1 |9|\n",
    "|F| 1| 11|\n",
    "|G |18| 10|\n",
    "|H| 12| 18|\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías requeridas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import warnings\n",
    "\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los datos\n",
    "J = 8 #Número de escuelas\n",
    "y = np.array([28.,  8., -3.,  7., -1.,  1., 18., 12.], dtype=np.float32) #Estimaciones de los efectos del tratamiento\n",
    "sigma = np.array([15., 10., 16., 11.,  9., 11., 10., 18.], dtype=np.float32) #Estimacion de la desviacion de los efectos del tratamiento\n",
    "schools = np.array(['Choate', 'Deerfield', 'Phillips Andover', 'Phillips Exeter',\n",
    "                    'Hotchkiss', 'Lawrenceville', \"St. Paul's\", 'Mt. Hermon'])\n",
    "\n",
    "schools_dat = {'J': J,\n",
    "               'y': y,\n",
    "               'sigma': sigma}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Implementación del modelo estadístico en TFP</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfd.JointDistributionSequential([\n",
    "  tfd.Normal(loc=0., scale=tf.math.sqrt(5.), name=\"mu\"),  # `mu` \n",
    "  tfd.HalfCauchy(loc=0., scale=5., name=\"tau\"),  # `Tau``\n",
    "  tfd.Independent(tfd.Normal(loc=tf.zeros(J),\n",
    "                             scale=tf.ones(J),\n",
    "                             name=\"eta\"),  # eta_i. Recordemos que eta_i es un vector\n",
    "                  reinterpreted_batch_ndims=1),\n",
    "  lambda eta, tau, mu: (\n",
    "      tfd.Independent(tfd.Normal(loc=(mu[..., tf.newaxis] +\n",
    "                                      tau[..., tf.newaxis]* \n",
    "                                      eta),  # `theta` \n",
    "                                 scale=sigma),\n",
    "                      name=\"y\",  # `y` \n",
    "                      reinterpreted_batch_ndims=1))\n",
    "])\n",
    "\n",
    "def target_log_prob_fn(mu, tau, eta):\n",
    "  \"\"\"Densidad objetivo no normalizada como función de estados.\"\"\"\n",
    "  return model.log_prob((\n",
    "      mu, tau, eta, sigma))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este código los parámetros que serán muestreados son $\\mu$ (*media global*), $\\tau$ (*desviación estándar*), y los $\\eta_i$ (*eta*) que son los efectos aleatorios en el modelo. Las medias $\\theta_i$ de las escuelas son calculados. Es decir, son funcionales de los parámetros.\n",
    "\n",
    "Hemos asumido las distribuciones a priori para $\\mu\\sim \\mathcal{N}(0,5)$,  $\\tau\\sim \\mathcal{Cauchy}(0,5)1_{\\tau>0.0}$ y $\\eta_i \\sim \\mathcal{N}(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Compilación del modelo</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_results = 500\n",
    "num_burnin_steps = 500\n",
    "\n",
    "# Mejorar el rendimiento rastreando el muestreador con `tf.function`\n",
    "# y compilarlo usando XLA.\n",
    "# autograph transforma un subconjunto de código de Python a TensorFlow\n",
    "#jit_compile compila la función usando XLA\n",
    "@tf.function(autograph=False, jit_compile=True)\n",
    "def do_sampling():\n",
    "    # Muestreador que usa cadenas de Markov\n",
    "  return tfp.mcmc.sample_chain(\n",
    "      num_results=num_results,\n",
    "      num_burnin_steps=num_burnin_steps,\n",
    "      # Representación de nuestra previa\n",
    "      current_state=[\n",
    "          tf.zeros([], name='mu_0'),\n",
    "          tf.zeros([], name='tau_0'),\n",
    "          tf.ones([J], name='eta_0'),\n",
    "      ],\n",
    "      kernel=tfp.mcmc.HamiltonianMonteCarlo(\n",
    "          # Devuelve la log-densidad de nuestra previa\n",
    "          target_log_prob_fn=target_log_prob_fn,\n",
    "          step_size=0.4,\n",
    "          num_leapfrog_steps=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, kernel_results = do_sampling()\n",
    "mu, tau, eta = states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Distribución Predictiva Posterior</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shape = [5000]\n",
    "\n",
    "_, _, _, predictive_effects = model.sample(\n",
    "    value=(tf.broadcast_to(np.mean(mu, 0), sample_shape),\n",
    "           tf.broadcast_to(np.mean(tau, 0), sample_shape),\n",
    "           tf.broadcast_to(np.mean(eta, 0),\n",
    "                           sample_shape + [J]),\n",
    "           None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Inferencia. InferenceData(ArviZ)</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seguir esta parte del tutorial localmente por favor instale ArviZ.\n",
    "\n",
    "Desde la linea de comandos: \n",
    "\n",
    "*pip install arviz*\n",
    "\n",
    "o mejor use\n",
    "\n",
    "*conda install -c conda-forge arviz*\n",
    "\n",
    "[InferenceData](https://arviz-devs.github.io/arviz/notebooks/InferenceDataCookbook.html) es la principal estructura de datos de ArviZ, la herramienta recomendada para nuestros análisis con TFP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías requeridas.\n",
    "\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray\n",
    "\n",
    "# definimos estilos para el fondo de los gráficos y para mostrar la información\n",
    "az.style.use('arviz-darkgrid')\n",
    "xarray.set_options(display_style=\"html\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_probability.python.edward2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14844/4239043162.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m tfp_data = az.from_tfp (\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mposterior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel_results\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mposterior_predictive_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcoords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'school'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mschools\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     dims={\n",
      "\u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\arviz\\data\\io_tfp.py\u001b[0m in \u001b[0;36mfrom_tfp\u001b[1;34m(posterior, var_names, model_fn, feed_dict, posterior_predictive_samples, posterior_predictive_size, chain_dim, observed, coords, dims)\u001b[0m\n\u001b[0;32m    199\u001b[0m ):\n\u001b[0;32m    200\u001b[0m     \u001b[1;34m\"\"\"Convert tfp data into an InferenceData object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m     return TfpConverter(\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[0mposterior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mposterior\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mvar_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvar_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\arviz\\data\\io_tfp.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, posterior, var_names, model_fn, feed_dict, posterior_predictive_samples, posterior_predictive_size, chain_dim, observed, coords, dims)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_probability\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_probability\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medward2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0med\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_probability.python.edward2'"
     ]
    }
   ],
   "source": [
    "tfp_data = az.from_tfp (\n",
    "    posterior = kernel_results,\n",
    "    posterior_predictive_samples=500,\n",
    "    coords={'school': schools }, \n",
    "    dims={\n",
    "        \"theta\": [\"school\"],\n",
    "        'y': ['school'],\n",
    "        'eta': ['school'],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_data.posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_data.posterior.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_data.posterior.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tfp_data.posterior.mu[0,300]\n",
    "print(val)\n",
    "print('np.array(val) = ' ,np.array(val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_data.sample_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_data.log_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_data.posterior_predictive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp_data.observed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_density(tfp_data, var_names=['mu', 'tau']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_density?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_density(tfp_data);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_autocorr(tfp_data, var_names=(\"tau\",\"mu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_autocorr?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_autocorr(tfp_data,max_lag=40,var_names=(\"tau\",\"mu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(tfp_data, var_names=(\"tau\",\"mu\",\"eta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(tfp_data, var_names=(\"tau\",\"mu\", \"eta\"),r_hat=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(tfp_data, var_names=(\"tau\",\"mu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_mcse(tfp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_mcse?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_pair(tfp_data, coords={\"school\": ['Choate', 'Deerfield', 'Phillips Andover']}, divergences=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.geweke(tfp_data.posterior.mu[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Referencias</span>\n",
    "\n",
    "- https://arviz-devs.github.io/arviz/getting_started/CreatingInferenceData.html#from-pyro"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
